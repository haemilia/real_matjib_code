{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c7b020",
   "metadata": {},
   "source": [
    "**참고 사이트**<br>\n",
    "[인스타 크롤링(1)](https://blog.naver.com/cygnet3rd/222885102852),\n",
    "[인스타 크롤링(2)](https://velog.io/@leeug9002/python-selenium%EC%9D%B8%EC%8A%A4%ED%83%80-%ED%81%AC%EB%A1%A4%EB%A7%81),\n",
    "[인스타 게시물 내 사진 크롤링](https://proefforter.tistory.com/36),\n",
    "[리스트 중복 제거&순서 유지](https://m31phy.tistory.com/130)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8f441",
   "metadata": {},
   "source": [
    "**필요한 패키지 호출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from re import escape\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import urllib.request\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd291a1e",
   "metadata": {},
   "source": [
    "**데이터 수집하기**\n",
    "- 아이디, 본문 내용, 해시태그, 댓글, 좋아요 수, 작성 날짜, 이미지 링크, 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(driver):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #아이디\n",
    "    ids = soup.select('span.xjp7ctv')[1].text\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #content\n",
    "    h1 = soup.select('h1._ap3a._aaco._aacu._aacx._aad7._aade')\n",
    "    text_before_a = str(h1).split('<a')[0]\n",
    "\n",
    "    if len(BeautifulSoup(text_before_a, 'html.parser').text) == 1:\n",
    "        text = ''\n",
    "    else:\n",
    "        text = BeautifulSoup(text_before_a, 'html.parser').text[1:-1]  #[, ] 제거\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #tags\n",
    "    ln = len(soup.select('h1._ap3a._aaco._aacu._aacx._aad7._aade > a'))\n",
    "\n",
    "    if ln > 0:\n",
    "        hashtags = soup.select('h1._ap3a._aaco._aacu._aacx._aad7._aade > a')\n",
    "        tags = []\n",
    "\n",
    "        for i in range(ln):\n",
    "            hashtag = hashtags[i].text\n",
    "            tags.append(hashtag)\n",
    "    else:\n",
    "        tags = ''\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #댓글\n",
    "    ln = len(soup.select('div.xt0psk2 > span'))\n",
    "\n",
    "    if ln > 0:\n",
    "        comments = soup.select('div.xt0psk2 > span')\n",
    "        cmts = []\n",
    "\n",
    "        for i in range(ln-1):\n",
    "            comment = comments[i].text\n",
    "            cmts.append(comment)\n",
    "\n",
    "    else:\n",
    "        cmts = ''\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #좋아요\n",
    "    likes = soup.select('span.html-span.xdj266r.x11i5rnm.xat24cr.x1mh8g0r.xexx8yu.x4uap5.x18d9i69.xkhd6sd.x1hl2dhg.x16tdsg8.x1vvkbs')[-1].text\n",
    "\n",
    "    if likes == '설정더 보기':\n",
    "        likes = 0\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #게시 날짜\n",
    "    date = soup.select('time.x1p4m5qa')[0]['datetime'][:10]\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #이미지 링크\n",
    "    test_img_urls = []\n",
    "    ln = len(soup.select('div._acnb'))  #이미지 2개 이상일 때 동그라미 개수\n",
    "\n",
    "    if ln > 0:\n",
    "        for i in range(ln):\n",
    "            img_containers = driver.find_elements(By.CSS_SELECTOR, 'li._acaz')\n",
    "            ln2 = len(img_containers)\n",
    "            for j in range(ln2):\n",
    "                try:\n",
    "                    img = img_containers[j].find_element(By.TAG_NAME, 'img')\n",
    "                    img_src = img.get_attribute('src')\n",
    "                    test_img_urls.append(img_src)\n",
    "                except:\n",
    "                    pass\n",
    "            time.sleep(2)\n",
    "            if i != ln-1:\n",
    "                driver.find_element(By.CLASS_NAME,\"_afxw._al46._al47\").click()  #다음 사진으로 이동\n",
    "    else:\n",
    "        img = driver.find_element(By.CSS_SELECTOR, 'div._aagv > img')\n",
    "        img_src = img.get_attribute('src')\n",
    "        test_img_urls.append(img_src)\n",
    "\n",
    "    img_urls = list(dict.fromkeys(test_img_urls))   #이미지 중복 제거, 원래 담았던 순서대로 정렬\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    #장소\n",
    "    try:\n",
    "        place = soup.select('div._ap3a._aacn._aacu._aacy._aada._aade')[0].text\n",
    "    except:\n",
    "        place = ''\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "    data = [ids, text, tags, cmts, likes, date, img_urls, place]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ed240",
   "metadata": {},
   "source": [
    "**크롬 브라우저 열고 인스타그램 접속**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f486f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "url = 'https://www.instagram.com'\n",
    "\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d831ef",
   "metadata": {},
   "source": [
    "**인스타그램 로그인**\n",
    "- `By.NAME`: HTML 태그 중 `name='...'` 속성을 기준으로 찾겠다\n",
    "- ex. `<input t ype='password' name='password'>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abba737",
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = 'user id'\n",
    "input_id = driver.find_element(By.NAME, 'username')\n",
    "input_id.clear()\n",
    "input_id.send_keys(userId)\n",
    "\n",
    "userPw = 'user password'\n",
    "input_pw = driver.find_element(By.NAME, 'password')\n",
    "input_pw.clear()\n",
    "input_pw.send_keys(userPw)\n",
    "input_pw.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2094f95",
   "metadata": {},
   "source": [
    "**연남동 일반 음식점 리스트(구글 기준) 데이터셋**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda439fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('real_matjib/data_collection/yeonnam_restaurant_reviews_googlemaps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd05f2",
   "metadata": {},
   "source": [
    "- 사업장명(가게 이름) 중복 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54113483",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_list = list(df['사업장명'].unique())\n",
    "\n",
    "#해시태그는 띄어쓰기 X\n",
    "for i in range(len(house_list)):\n",
    "    house_list[i] = house_list[i].replace(' ', '')    #문자열 내부 공백 제거\n",
    "\n",
    "len(house_list) #630"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e7f71",
   "metadata": {},
   "source": [
    "- 잘 되고 있는지 원활한 점검을 위해 10개씩 끊기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_house_lists = {}\n",
    "\n",
    "for i in range(1, 64):\n",
    "    start = (i-1) * 10\n",
    "    end = i*10\n",
    "\n",
    "    exp_house_lists[i] = house_list[start:end]  #house_list 10개씩 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb58f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "result_df = {}\n",
    "\n",
    "for i in range(1, 64):\n",
    "    results[i] = []\n",
    "\n",
    "    for exp in exp_house_lists[i]:\n",
    "        #검색창 버튼 클릭\n",
    "        search_btn = driver.find_elements(By.CSS_SELECTOR, 'div.x1iyjqo2.xh8yej3 > div')[1]\n",
    "        search_btn.click()\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "        #검색할 해시태그\n",
    "        no_parens = re.sub(r'\\(.*?\\)', '', exp) #1단계: 괄호와 그 안의 내용 제거\n",
    "        clean = re.sub(r'[^가-힣a-zA-Z]', '', no_parens)    #2단계: 한글, 영문 외의 모든 문자 제거\n",
    "        search = '#' + clean\n",
    "        tag_input = driver.find_element(By.CSS_SELECTOR, 'div.xjoudau.x6s0dn4.x78zum5.xdt5ytf.x1c4vz4f.xs83m0k.xrf2nzk.x1n2onr6.xh8yej3.x1hq5gj4 > input')\n",
    "        tag_input.send_keys(search) #html의 input 태그로 전송\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "        #검색 시 해시태그 존재 O\n",
    "        try:\n",
    "            #첫 번째 해시태그 url로 이동, 해시태그 가져오기\n",
    "            go_first_tag = driver.find_element(By.CSS_SELECTOR, 'div.x9f619.x78zum5.xdt5ytf.x1iyjqo2.x6ikm8r.x1odjw0f.xh8yej3.xocp1fn > a')\n",
    "            first_tag_name = driver.find_element(By.CSS_SELECTOR, 'div.x9f619.xjbqb8w.x78zum5.x168nmei.x13lgxp2.x5pf9jr.xo71vjh.x1uhb9sk.x1plvlek.xryxfnj.x1iyjqo2.x2lwn1j.xeuugli.xdt5ytf.xqjyukv.x1cy8zhl.x1oa3qoh.x1nhvcw1 > span > span').text\n",
    "            tag_name = first_tag_name.lstrip('#')   #해시태그 지우기\n",
    "            time.sleep(3)\n",
    "            ActionChains(driver).move_to_element(go_first_tag).click().perform()\n",
    "\n",
    "            time.sleep(8)\n",
    "\n",
    "            #첫 번째 게시물 클릭: 만약 검색한 사업장명이 그대로 안 나올 경우 연관검색어 순위가 가장 높은 걸로 검색\n",
    "            go_first_post = driver.find_element(By.CSS_SELECTOR, 'div._aagw')\n",
    "            time.sleep(3)\n",
    "            ActionChains(driver).move_to_element(go_first_post).click().perform()   #검색 후 첫 번째 게시물 강제 클릭\n",
    "\n",
    "            time.sleep(3) \n",
    "            \n",
    "            ln = len(driver.find_elements(By.CSS_SELECTOR, 'div._aagw')) -1\n",
    "            target = 10 #스크롤링할 게시물 개수\n",
    "\n",
    "            if ln >= target:\n",
    "                for j in range(target):\n",
    "                    data = get_content(driver)\n",
    "                    data.insert(0, exp)   #첫 번째 자리에 '사업장명' 추가\n",
    "                    data.insert(1, tag_name)    #검색한 태그 네임 추가\n",
    "                    results[i].append(data)\n",
    "                    if i != target-1:\n",
    "                        #다음 게시물로 이동\n",
    "                        go_nxt_post = driver.find_elements(By.CSS_SELECTOR, 'div._aaqg._aaqh > button')[0]\n",
    "                        time.sleep(2)\n",
    "                        go_nxt_post.click()\n",
    "                    time.sleep(4)\n",
    "            else:\n",
    "                for j in range(ln):\n",
    "                    data = get_content(driver)\n",
    "                    data.insert(0, exp)    #첫 번째 자리에 '사업장명' 추가\n",
    "                    data.insert(1, tag_name)    #검색한 태그 네임 추가\n",
    "                    results[i].append(data)\n",
    "                    if i != ln-1:\n",
    "                        #다음 게시물로 이동\n",
    "                        go_nxt_post = driver.find_elements(By.CSS_SELECTOR, 'div._aaqg._aaqh > button')[0]\n",
    "                        time.sleep(2)\n",
    "                        go_nxt_post.click()\n",
    "                    time.sleep(4)\n",
    "\n",
    "        #검색 시 해시태그 존재 X\n",
    "        except Exception as e:\n",
    "            print(exp)\n",
    "            print(e)\n",
    "\n",
    "        #홈 화면으로 이동\n",
    "        home = 'https://www.instagram.com/'\n",
    "        driver.get(home)\n",
    "        time.sleep(3)\n",
    "\n",
    "    result_df[i] = pd.DataFrame(results[i])\n",
    "    result_df[i].columns = ['food_house', 'search', 'ids', 'text', 'tags', 'cmts', 'likes', 'date', 'img_urls', 'place']\n",
    "    result_df[i].to_excel(f'result_df{i}.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a37cdc",
   "metadata": {},
   "source": [
    "**데이터프레임 병합**\n",
    "- 데이터 수집 잘 됐는지 확인했으면, 데이터프레임 하나로 병합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7288ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [pd.read_excel(f'../../result_df{i}.xlsx') for i in range(1, 64)],\n",
    "    axis=0,\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "df.to_excel('../dataset/instagram_tags.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7bcb7",
   "metadata": {},
   "source": [
    "**데이터프레임 `Duck DB` 파일로 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cc3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c59b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../dataset/instagram_tags.xlsx')\n",
    "\n",
    "con = duckdb.connect(\"../dataset/instagram_tags.duckdb\")\n",
    "con.execute(\"CREATE OR REPLACE TABLE my_table AS SELECT * FROM df\")\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real_matjib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
